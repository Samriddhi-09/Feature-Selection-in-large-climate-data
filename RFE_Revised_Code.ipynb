{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e382ef4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "df = pd.read_pickle(\"C:\\\\Users\\\\samri\\\\Desktop\\\\IISERB\\\\merged_data.pickle\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f068d35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samri\\AppData\\Local\\Temp\\ipykernel_7632\\2049928907.py:1: UserWarning: Parsing dates in %d-%m-%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  df_new = df[(df['time']>=pd.to_datetime('01-01-1979'))& (df['time']<=pd.to_datetime('31-12-2014'))]\n"
     ]
    }
   ],
   "source": [
    "df_new = df[(df['time']>=pd.to_datetime('01-01-1979'))& (df['time']<=pd.to_datetime('31-12-2014'))]\n",
    "\n",
    "# Independent variables (everything except 'prec')\n",
    "X = df_new.drop(columns=['prec', 'lat', 'lon', 'time','tcrw', 'tclw'])\n",
    "\n",
    "\n",
    "# Dependent variable\n",
    "y = df_new['prec']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de8dbc22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)  # where X is your feature DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbde7de0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [19:42:58] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\samri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\sklearn.py:1478: UserWarning: [19:43:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  score = b.get_score(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” Top 10 Features by Absolute % Contribution (Trained on All Features):\n",
      "   Feature  Importance (%)\n",
      "33    vimd           41.52\n",
      "14    q500           12.24\n",
      "28     ttr           12.24\n",
      "34    w500            7.21\n",
      "22    tcwv            5.98\n",
      "35    w850            3.52\n",
      "17    r850            3.10\n",
      "23     tcw            2.65\n",
      "13     pev            1.98\n",
      "26     tsr            1.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\core.py:729: UserWarning: [19:43:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  return func(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š Model Evaluation Metrics:\n",
      "ðŸ”¹ MSE: 4.6390\n",
      "ðŸ”¹ RMSE: 2.1538\n",
      "ðŸ”¹ MAE: 0.6652\n",
      "ðŸ”¹ RÂ² Score: 0.9405\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define model\n",
    "xgb_gpu = XGBRegressor(\n",
    "    tree_method='gpu_hist',\n",
    "    max_depth=6,\n",
    "    n_estimators=100,\n",
    "    subsample=0.7,\n",
    "    colsample_bytree=0.7,\n",
    "    verbosity=1 ,\n",
    "    random_state=42,\n",
    "    learning_rate=0.1\n",
    ")\n",
    "\n",
    "xgb_gpu.fit(X_train, y_train)  \n",
    "\n",
    "\n",
    "# âœ… Get feature importances for all features\n",
    "importances = xgb_gpu.feature_importances_\n",
    "importances_percent = 100 * importances / importances.sum()\n",
    "\n",
    "# Create DataFrame\n",
    "feature_names = ['100u', '100v', '10u', '10v', 'cape', 'cdir', 'hcc', 'ishf', 'laihv', 'lailv', 'lcc', 'mcc', 'msl', 'pev', 'q500', 'q850', \n",
    "'r500', 'r850', 't2m', 't500', 't850', 'tcc', 'tcwv', 'tcw', 'tisr', 'tsrc', 'tsr', 'ttrc', 'ttr', 'u500', 'u850', 'v500', 'v850', 'vimd', 'w500',\n",
    "'w850', 'z500', 'z850']\n",
    "\n",
    "X = pd.DataFrame(X, columns=feature_names)\n",
    "\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance (%)': importances_percent\n",
    "}).sort_values(by='Importance (%)', ascending=False)\n",
    "\n",
    "# âœ… Display top 10 features\n",
    "top_10 = importance_df.head(10)\n",
    "print(\"ðŸ” Top 10 Features by Absolute % Contribution (Trained on All Features):\")\n",
    "print(top_10.round(2))\n",
    "\n",
    "# âœ… Predict and Evaluate\n",
    "y_pred = xgb_gpu.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"\\nðŸ“Š Model Evaluation Metrics:\")\n",
    "print(f\"ðŸ”¹ MSE: {mse:.4f}\")\n",
    "print(f\"ðŸ”¹ RMSE: {rmse:.4f}\")\n",
    "print(f\"ðŸ”¹ MAE: {mae:.4f}\")\n",
    "print(f\"ðŸ”¹ RÂ² Score: {r2:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "#print(type(xgb_gpu))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05f1cf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samri\\AppData\\Local\\Temp\\ipykernel_4376\\1227539244.py:8: UserWarning: Parsing dates in %d-%m-%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  df_new = df[(df['time']>=pd.to_datetime('01-01-1979'))& (df['time']<=pd.to_datetime('31-12-2014'))]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Variable           VIF\n",
      "0     const  9.585319e+06\n",
      "1      100u  9.376724e+01\n",
      "2      100v  4.605282e+01\n",
      "3       10u  9.570028e+01\n",
      "4       10v  4.659250e+01\n",
      "5      cape  2.656205e+00\n",
      "6      cdir  3.362603e+01\n",
      "7       hcc  2.430502e+01\n",
      "8      ishf  4.870999e+00\n",
      "9     laihv  1.273188e+00\n",
      "10    lailv  1.946299e+00\n",
      "11      lcc  5.227938e+00\n",
      "12      mcc  7.961986e+00\n",
      "13      msl  3.864254e+02\n",
      "14      pev  2.800381e+01\n",
      "15     q500  5.382549e+01\n",
      "16     q850  1.098951e+02\n",
      "17     r500  3.030600e+01\n",
      "18     r850  5.780887e+01\n",
      "19      t2m  7.265065e+01\n",
      "20     t500  1.828165e+01\n",
      "21     t850  4.618843e+01\n",
      "22      tcc  2.827495e+01\n",
      "23     tcwv  1.435041e+04\n",
      "24      tcw  1.449401e+04\n",
      "25     tisr  1.783504e+02\n",
      "26     tsrc  1.900941e+02\n",
      "27      tsr  2.671892e+01\n",
      "28     ttrc  1.737500e+01\n",
      "29      ttr  1.668382e+01\n",
      "30     u500  4.933437e+00\n",
      "31     u850  5.130528e+00\n",
      "32     v500  1.653237e+00\n",
      "33     v850  2.946564e+00\n",
      "34     vimd  2.670039e+00\n",
      "35     w500  2.488854e+00\n",
      "36     w850  1.221705e+00\n",
      "37     z500  1.637437e+01\n",
      "38     z850  2.101464e+02\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "df = pd.read_pickle(\"C:\\\\Users\\\\samri\\\\Desktop\\\\IISERB\\\\merged_data.pickle\")\n",
    "\n",
    "df_new = df[(df['time']>=pd.to_datetime('01-01-1979'))& (df['time']<=pd.to_datetime('31-12-2014'))]\n",
    "\n",
    "# Independent variables (everything except 'prec')\n",
    "X = df_new.drop(columns=['prec', 'lat', 'lon', 'time','tcrw', 'tclw'])\n",
    "\n",
    "\n",
    "# Dependent variable\n",
    "y = df_new['prec']\n",
    "\n",
    "# Sample 10,000 rows from X and y together\n",
    "sample_indices = np.random.choice(X.shape[0], size=100000, replace=False)\n",
    "\n",
    "X_sampled = X.iloc[sample_indices].reset_index(drop=True)\n",
    "\n",
    "\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from statsmodels.tools.tools import add_constant\n",
    "\n",
    "# Suppose X already contains your independent variables\n",
    "# For example:\n",
    "# X = df.drop(columns=['target'])  # if you want to exclude the dependent variable\n",
    "\n",
    "# Add constant for intercept\n",
    "X_const = add_constant(X_sampled)\n",
    "\n",
    "# Calculate VIF\n",
    "vif_data = pd.DataFrame({\n",
    "    \"Variable\": X_const.columns,\n",
    "    \"VIF\": [variance_inflation_factor(X_const.values, i) for i in range(X_const.shape[1])]\n",
    "})\n",
    "\n",
    "print(vif_data)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
